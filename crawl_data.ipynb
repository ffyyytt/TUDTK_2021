{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb9d04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import *\n",
    "from pyflightdata import FlightData\n",
    "from pyflightdata.common_fr24 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e52567",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = \"20210101\"\n",
    "END_DATE = \"20210430\"\n",
    "use_country = True\n",
    "countries = [\"Canada\"]\n",
    "\n",
    "ERROR_LOG_FILE_NAME = 'logs/error.log'\n",
    "DEBUG_LOG_FILE_NAME = 'logs/debug.log'\n",
    "INFO_LOG_FILE_NAME = 'logs/info.log'\n",
    "\n",
    "COUNTRIES_FILE_NAME = \"datasets/countries.txt\"\n",
    "GRAPH_ATTRIBUTES_FILE_NAME = \"datasets/graph_attributes.txt \"\n",
    "EDGE_LIST_FILE_PREFIX = \"dataset/\"\n",
    "\n",
    "ADDITIONAL_AIRPORTS_FILE_NAME = \"datasets/additional_airports.txt\"\n",
    "\n",
    "AIRPORTS_FILE_PREFIX = \"datasets/airports/node_attributes\"\n",
    "UNIQUE_FLIGHTS_FILE_PREFIX = \"datasets/unique_flights/unique_flights\"\n",
    "UNIQUE_FLIGHTS_LOG_FLIE_NAME = UNIQUE_FLIGHTS_FILE_PREFIX + \".log\"\n",
    "HISTORIC_FLIGHTS_FILE_PREFIX = \"datasets/historic_flights/historic_flights\"\n",
    "\n",
    "AIRPORT_ATTRIBUTE_NAMES = [\"iata\", \"latitude\", \"longitude\", \"country\", \"city\"]\n",
    "FLIGHTS_ATTRIBUTE_NAMES = [\"flight_number\", \"status\", \"departure_airport\", \"arrival_airport\", \"departure_date\", \"duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd2e6444",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfoFilter(logging.Filter):\n",
    "    def filter(self, rec):\n",
    "        return rec.levelno == logging.INFO\n",
    "\n",
    "def get_logger(info_log_file, error_log_file_name):\n",
    "    log = logging.getLogger('default_logger')\n",
    "    # set console to info\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.addFilter(InfoFilter())\n",
    "    log.addHandler(console_handler)\n",
    "    # set info log to info\n",
    "    file_handler_info = logging.FileHandler(info_log_file, mode='w')\n",
    "    file_handler_info.addFilter(InfoFilter())\n",
    "    log.addHandler(file_handler_info)\n",
    "    # set error log to warn\n",
    "    file_handler_error = logging.FileHandler(error_log_file_name, mode='w')\n",
    "    file_handler_error.setLevel(logging.WARNING)\n",
    "    log.addHandler(file_handler_error)\n",
    "    log.setLevel(logging.DEBUG)\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bc10d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFR24(FR24):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CustomFR24, self).__init__()\n",
    "\n",
    "    def get_airport_departures_total_page(self, url):\n",
    "        while True:\n",
    "            try:\n",
    "                return self.get_raw_data_json(url, 'result.response.airport.pluginData.schedule.departures.page.total')[0]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def get_airport_arrivals_total_page(self, url):\n",
    "        while True:\n",
    "            try:\n",
    "                return self.get_raw_data_json(url, 'result.response.airport.pluginData.schedule.arrivals.page.total')[0]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def get_data(self, url, by_tail=False):\n",
    "        response = self.get_raw_data_json(url, 'result.response')\n",
    "        response = self.filter_and_get_data(response) or []\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "244f76a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFlightData(FlightData):\n",
    "\n",
    "    _fr24 = CustomFR24()\n",
    "    _FLT_BASE = 'https://api.flightradar24.com/common/v1/flight/list.json?query={0}&fetchBy=flight&filterBy=historic&page={2}&limit={3}&token={1}&timestamp={4}'\n",
    "\n",
    "    def __init__(self, email=None, password=None):\n",
    "        super(CustomFlightData, self).__init__(email, password)\n",
    "\n",
    "    def get_airport_details(self, iata, page=1, limit=100):\n",
    "        url = AIRPORT_DATA_BASE.format(iata, str(self.AUTH_TOKEN), page, limit)\n",
    "        details = self._fr24.get_airport_details(url)\n",
    "        return details\n",
    "\n",
    "    def get_airport_departures_total_page(self, iata, page=1, limit=100):\n",
    "        date = datetime.datetime.now()\n",
    "        url = AIRPORT_DATA_BASE_EARLIER.format(iata, str(self.AUTH_TOKEN), page, limit, int(date.timestamp()), 0)\n",
    "        return self._fr24.get_airport_departures_total_page(url)\n",
    "\n",
    "    def get_airport_arrivals_total_page(self, iata, page=1, limit=100):\n",
    "        date = datetime.datetime.now()\n",
    "        url = AIRPORT_DATA_BASE_EARLIER.format(iata, str(self.AUTH_TOKEN), page, limit, int(date.timestamp()), 0)\n",
    "        return self._fr24.get_airport_arrivals_total_page(url)\n",
    "\n",
    "    def get_airport_departures(self, iata, page=1, limit=100, earlier_data=False):\n",
    "        date = datetime.datetime.now()\n",
    "        url = AIRPORT_DATA_BASE_EARLIER.format(iata, str(self.AUTH_TOKEN), page, limit, int(date.timestamp()), 0)\n",
    "        return self._fr24.get_airport_departures(url)\n",
    "\n",
    "    def get_airport_arrivals(self, iata, page=1, limit=100, earlier_data=False):\n",
    "        date = datetime.datetime.now()\n",
    "        url = AIRPORT_DATA_BASE_EARLIER.format(iata, str(self.AUTH_TOKEN), page, limit, int(date.timestamp()), 0)\n",
    "        return self._fr24.get_airport_arrivals(url)\n",
    "\n",
    "    def get_historical_flight_number(self, flight_number, last_updated, page=1, limit=100):\n",
    "        url = self._FLT_BASE.format(flight_number, str(self.AUTH_TOKEN), page, limit, last_updated)\n",
    "        return self._fr24.get_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c4df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_countries():\n",
    "    logging.basicConfig(filename=ERROR_LOG_FILE_NAME, level=logging.WARNING)\n",
    "    f = CustomFlightData()\n",
    "    countries = [country['country'] for country in tqdm(f.get_countries())]\n",
    "    df = pd.DataFrame(countries)\n",
    "    df.to_csv(COUNTRIES_FILE_NAME, header=False, index=False)\n",
    "\n",
    "if (not os.path.exists(COUNTRIES_FILE_NAME[:COUNTRIES_FILE_NAME.rfind(\"/\")])):\n",
    "    os.makedirs(COUNTRIES_FILE_NAME[:COUNTRIES_FILE_NAME.rfind(\"/\")])\n",
    "    os.makedirs(ERROR_LOG_FILE_NAME[:ERROR_LOG_FILE_NAME.rfind(\"/\")])\n",
    "    write_countries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da173b90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_airport(airport_details):\n",
    "    try:\n",
    "        airport_dict = {\n",
    "            'iata': airport_details['code']['iata'],\n",
    "            'latitude': airport_details['position']['latitude'],\n",
    "            'longitude': airport_details['position']['longitude'],\n",
    "            'country': airport_details['position']['country']['name'],\n",
    "            'city': airport_details['position']['region']['city']\n",
    "        }\n",
    "        return airport_dict\n",
    "    except (KeyError, TypeError):\n",
    "        logging.error(\"Error parsing airport %s\", airport_details)\n",
    "        return None\n",
    "\n",
    "\n",
    "def to_flight_number(departure):\n",
    "    try:\n",
    "        flight_number = departure['flight']['identification']['number']['default']\n",
    "        return flight_number\n",
    "    except (KeyError, TypeError):\n",
    "        logging.error(\"Error parsing flight_number %s\", departure)\n",
    "        return None\n",
    "\n",
    "\n",
    "def to_has_more(history_by_flight_number):\n",
    "    try:\n",
    "        has_more = history_by_flight_number['page']['more']\n",
    "        return has_more\n",
    "    except (KeyError, TypeError):\n",
    "        logging.error(\"Error parsing has_more %s\", history_by_flight_number)\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_departure_date(flight):\n",
    "    if flight['time']['real'][\"departure\"] != 'None':\n",
    "        date = flight['time']['real']['departure_date']\n",
    "    else:\n",
    "        date = flight['time']['scheduled']['departure_date']\n",
    "    datetime.datetime.strptime(date, '%Y%m%d')\n",
    "    return date\n",
    "\n",
    "\n",
    "def to_flight(flight):\n",
    "    try:\n",
    "        flight_dict = {\n",
    "            'flight_number': flight['identification']['number']['default'],\n",
    "            'status': flight['status']['generic']['status']['text'],\n",
    "            'departure_airport': flight['airport']['origin']['code']['iata'],\n",
    "            'arrival_airport': flight['airport']['destination']['code']['iata'],\n",
    "            'departure_date': get_departure_date(flight),\n",
    "            'time_updated': flight['time']['other']['updated'],\n",
    "            \"duration\": flight['time']['other']['duration']\n",
    "        }\n",
    "        return flight_dict\n",
    "    except (KeyError, TypeError, ValueError):\n",
    "        logging.error(\"Error parsing flight %s\", flight)\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_airport_by_iata(f, iata):\n",
    "    airport_details = f.get_airport_details(iata)\n",
    "    return to_airport(airport_details)\n",
    "\n",
    "\n",
    "def fetch_airports_by_country(f, airports_file_prefix, country):\n",
    "    filename = \"%s-%s.txt\" % (airports_file_prefix, country)\n",
    "    if not os.path.exists(filename):\n",
    "        airports = []\n",
    "        for airport in f.get_airports(country):\n",
    "            if airport['iata']:\n",
    "                airport_dict = get_airport_by_iata(f, airport['iata'])\n",
    "                if airport_dict is not None:\n",
    "                    airports.append(airport_dict)\n",
    "            else:\n",
    "                logging.warning(\"IATA not found for airport: %s\", airport)\n",
    "        df = pd.DataFrame(airports)\n",
    "        df.to_csv(filename, header=False)\n",
    "    else:\n",
    "        logging.warning(\"airports file %s already exists: \" % filename)\n",
    "\n",
    "\n",
    "def fetch_airports(countries,\n",
    "                   airports_file_prefix=AIRPORTS_FILE_PREFIX,\n",
    "                   error_log_file_name=ERROR_LOG_FILE_NAME):\n",
    "    logging.basicConfig(filename=error_log_file_name, level=logging.WARNING)\n",
    "    f = CustomFlightData()\n",
    "    #f.login(\"username\", \"password\")\n",
    "    \n",
    "    if (not os.path.exists(airports_file_prefix[:airports_file_prefix.rfind(\"/\")])):\n",
    "        os.makedirs(airports_file_prefix[:airports_file_prefix.rfind(\"/\")])\n",
    "        if not countries:\n",
    "            countries = [country['country'] for country in f.get_countries()]\n",
    "        for country in tqdm(countries):\n",
    "            fetch_airports_by_country(f, airports_file_prefix, country)\n",
    "    f.logout()\n",
    "\n",
    "\n",
    "fetch_airports([], AIRPORTS_FILE_PREFIX, ERROR_LOG_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b2c554b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fetching the unique flights of: Canada\n",
      "loading airports\n",
      "total airports: 246\n",
      "  4%|▎         | 9/246 [00:23<07:52,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 35/246 [02:35<05:21,  1.53s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 73/246 [05:02<05:39,  1.96s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 520 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 97/246 [06:29<03:35,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n",
      "HTML code 429 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [15:18<00:00,  3.73s/it]\n",
      "total new flights: 1466\n",
      "total existing flights: 0\n",
      "total unique new flights: 1466\n"
     ]
    }
   ],
   "source": [
    "def get_unique_flights_logger(unique_flights_log_file_name):\n",
    "    unique_flights_logger = logging.getLogger('unique_flights_logger')\n",
    "    handler = logging.FileHandler(unique_flights_log_file_name, mode='a')\n",
    "    handler.addFilter(InfoFilter())\n",
    "    unique_flights_logger.addHandler(handler)\n",
    "    unique_flights_logger.setLevel(logging.INFO)\n",
    "    return unique_flights_logger\n",
    "\n",
    "\n",
    "def fetch_unique_flights(countries,\n",
    "                         unique_flights_file_prefix=UNIQUE_FLIGHTS_FILE_PREFIX,\n",
    "                         airports_file_prefix=AIRPORTS_FILE_PREFIX):\n",
    "    f = CustomFlightData()\n",
    "    #f.login(\"username\", \"password\")\n",
    "    if not countries:\n",
    "        default_logger.info(\"fetching countries\")\n",
    "        countries = [country['country'] for country in f.get_countries()]\n",
    "    for country in countries:\n",
    "        fetch_unique_flights_by_country(f, airports_file_prefix, unique_flights_file_prefix, country)\n",
    "    f.logout()\n",
    "\n",
    "\n",
    "def fetch_unique_flights_by_country(f, airports_file_prefix, unique_flights_file_prefix, country):\n",
    "    default_logger.info(\"fetching the unique flights of: %s\" % country)\n",
    "    airports_file_name = \"%s-%s.txt\" % (airports_file_prefix, country)\n",
    "    airports_file_name = airports_file_name\n",
    "    unique_flights_filename = \"%s-%s.txt\" % (unique_flights_file_prefix, country)\n",
    "    if os.path.exists(airports_file_name):\n",
    "        default_logger.info(\"loading airports\")\n",
    "        airports = pd.read_csv(airports_file_name, names=AIRPORT_ATTRIBUTE_NAMES)\n",
    "        default_logger.info(\"total airports: %d\" % len(airports))\n",
    "        new_flights = get_new_flights(f, airports)\n",
    "        existing_flights_df = get_existing_flights(unique_flights_filename)\n",
    "        flights_added, total_flights = append_new_flights(existing_flights_df, new_flights, unique_flights_filename)\n",
    "        unique_flights_logger.info(\"%s, %s, %d, %d\" % (pd.to_datetime('today'), country, flights_added, total_flights))\n",
    "    else:\n",
    "        default_logger.warning(\"airports file %s does not exist: \" % airports_file_name)\n",
    "\n",
    "\n",
    "def get_new_flights(f, airports):\n",
    "    num_airports = len(airports)\n",
    "    new_flights = set()\n",
    "    for airport_idx, airport in enumerate(tqdm(airports['iata'])):\n",
    "        fetch_unique_flights_by_airport(f, airport, new_flights)\n",
    "    return new_flights\n",
    "\n",
    "\n",
    "def fetch_unique_flights_by_airport(f, airport, new_flights):\n",
    "    total_page = f.get_airport_departures_total_page(airport)\n",
    "    for page in range(1, total_page + 1):\n",
    "        for flight in f.get_airport_departures(airport, page=page, earlier_data=True):\n",
    "            append_flight(flight, new_flights)\n",
    "\n",
    "    total_page = f.get_airport_arrivals_total_page(airport)\n",
    "    for page in range(1, total_page + 1):\n",
    "        for flight in f.get_airport_arrivals(airport, page=page, earlier_data=True):\n",
    "            append_flight(flight, new_flights)\n",
    "\n",
    "\n",
    "def append_flight(flight, new_flights):\n",
    "    flight_number = to_flight_number(flight)\n",
    "    if flight_number is not None:\n",
    "        new_flights.add(flight_number)\n",
    "\n",
    "\n",
    "def get_existing_flights(unique_flights_filename):\n",
    "    existing_flights_df = pd.DataFrame(columns=['flight', 'added'])\n",
    "    if os.path.exists(unique_flights_filename):\n",
    "        existing_flights_df = pd.read_csv(unique_flights_filename, names=['flight', 'added'])\n",
    "        existing_flights_df.added = existing_flights_df.added.fillna(pd.to_datetime('today'))\n",
    "    return existing_flights_df\n",
    "\n",
    "\n",
    "def append_new_flights(existing_flights_df, new_flights, unique_flights_filename):\n",
    "    default_logger.info(\"total new flights: %d\" % len(new_flights))\n",
    "    existing_flights = set(existing_flights_df['flight'].tolist())\n",
    "    default_logger.info(\"total existing flights: %d\" % len(existing_flights))\n",
    "    flights_to_add = new_flights.difference(existing_flights)\n",
    "    default_logger.info(\"total unique new flights: %d\" % len(flights_to_add))\n",
    "    flights_to_add_df = pd.DataFrame(flights_to_add, columns=['flight'])\n",
    "    flights_to_add_df['added'] = pd.to_datetime('today')\n",
    "    unique_flights_df = existing_flights_df.append(flights_to_add_df, ignore_index=True)\n",
    "    unique_flights_df.to_csv(unique_flights_filename, header=False, index=False)\n",
    "    return len(flights_to_add), len(unique_flights_df.index)\n",
    "\n",
    "if (not os.path.exists(UNIQUE_FLIGHTS_LOG_FLIE_NAME[:UNIQUE_FLIGHTS_LOG_FLIE_NAME.rfind(\"/\")])):\n",
    "    os.makedirs(UNIQUE_FLIGHTS_LOG_FLIE_NAME[:UNIQUE_FLIGHTS_LOG_FLIE_NAME.rfind(\"/\")])\n",
    "    \n",
    "    default_logger = get_logger(INFO_LOG_FILE_NAME, ERROR_LOG_FILE_NAME)\n",
    "    unique_flights_logger = get_unique_flights_logger(UNIQUE_FLIGHTS_LOG_FLIE_NAME)\n",
    "    fetch_unique_flights(countries, UNIQUE_FLIGHTS_FILE_PREFIX, AIRPORTS_FILE_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5bebabf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fetching flight history for country: Canada\n",
      "fetching flight history for country: Canada\n",
      "  1%|          | 8/1465 [00:11<39:39,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 15/1465 [00:32<38:05,  1.58s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 33/1465 [01:09<29:50,  1.25s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 47/1465 [01:37<27:19,  1.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 56/1465 [01:59<33:54,  1.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 66/1465 [02:27<29:47,  1.28s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 76/1465 [02:53<32:53,  1.42s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 88/1465 [03:22<30:13,  1.32s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 95/1465 [03:46<42:36,  1.87s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 110/1465 [04:19<24:47,  1.10s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 124/1465 [04:46<20:43,  1.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 132/1465 [05:09<38:07,  1.72s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 155/1465 [05:44<29:50,  1.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 186/1465 [06:33<20:57,  1.02it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 200/1465 [07:05<32:26,  1.54s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 209/1465 [07:27<23:53,  1.14s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 216/1465 [07:47<39:53,  1.92s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 233/1465 [08:17<17:41,  1.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 251/1465 [08:51<14:20,  1.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 281/1465 [09:50<33:12,  1.68s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 287/1465 [10:16<51:27,  2.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 301/1465 [10:46<21:58,  1.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 314/1465 [11:14<29:12,  1.52s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 336/1465 [12:00<22:56,  1.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 356/1465 [12:39<27:56,  1.51s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 374/1465 [13:09<17:38,  1.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 382/1465 [13:28<23:38,  1.31s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 393/1465 [13:55<23:49,  1.33s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 418/1465 [14:53<26:36,  1.53s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 425/1465 [15:14<31:47,  1.83s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 436/1465 [15:42<19:37,  1.14s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 444/1465 [16:03<30:13,  1.78s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 458/1465 [16:34<18:39,  1.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 472/1465 [17:00<15:11,  1.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 490/1465 [17:42<36:22,  2.24s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 509/1465 [18:29<18:32,  1.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 528/1465 [18:58<16:53,  1.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 563/1465 [20:08<18:15,  1.21s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 570/1465 [20:28<22:59,  1.54s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 579/1465 [20:49<22:06,  1.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 594/1465 [21:23<22:32,  1.55s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 607/1465 [21:51<15:32,  1.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 613/1465 [22:10<30:55,  2.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 635/1465 [22:50<19:00,  1.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 651/1465 [23:21<15:17,  1.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 661/1465 [23:50<25:28,  1.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 673/1465 [24:16<16:02,  1.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 676/1465 [24:34<47:16,  3.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 689/1465 [25:02<13:49,  1.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 697/1465 [25:26<22:38,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 708/1465 [25:50<20:26,  1.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 717/1465 [26:10<19:34,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 730/1465 [26:41<16:48,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 741/1465 [27:06<13:24,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 759/1465 [27:38<10:51,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 783/1465 [28:28<12:50,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 795/1465 [28:52<10:34,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 800/1465 [29:10<24:14,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 804/1465 [29:27<31:14,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 810/1465 [29:46<21:13,  1.94s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 821/1465 [30:14<20:39,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 828/1465 [30:43<25:52,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 841/1465 [31:14<17:05,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 866/1465 [32:02<14:50,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 884/1465 [32:33<07:41,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 893/1465 [33:03<22:28,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 906/1465 [33:29<09:32,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 920/1465 [33:59<10:12,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 930/1465 [34:21<09:26,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 942/1465 [34:46<09:46,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 962/1465 [35:26<11:10,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 978/1465 [35:58<09:17,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 991/1465 [36:24<10:28,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 1013/1465 [37:04<09:33,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1032/1465 [37:42<09:06,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1041/1465 [38:06<10:34,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1053/1465 [38:41<08:34,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1058/1465 [38:58<15:28,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1073/1465 [39:33<06:20,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1084/1465 [40:01<07:39,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1091/1465 [40:24<11:55,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1106/1465 [40:55<05:32,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1126/1465 [41:31<07:30,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1134/1465 [41:50<07:41,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 1154/1465 [42:34<06:34,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 1167/1465 [43:03<07:15,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1182/1465 [43:37<05:26,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1205/1465 [44:18<07:10,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1211/1465 [44:36<07:24,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1258/1465 [45:52<04:41,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 1267/1465 [46:16<05:23,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1276/1465 [46:42<05:48,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1287/1465 [47:07<04:13,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1305/1465 [47:49<04:16,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1317/1465 [48:22<03:27,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1330/1465 [48:50<02:35,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1351/1465 [49:28<02:29,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1377/1465 [50:12<02:51,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1399/1465 [50:55<01:42,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1422/1465 [51:37<01:09,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1438/1465 [52:09<00:32,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1454/1465 [52:39<00:15,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML code 402 - Retry in 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1465/1465 [53:06<00:00,  2.18s/it]\n"
     ]
    }
   ],
   "source": [
    "def update_count_by_flight_status(flight, count_by_flight_status):\n",
    "    status = flight['status']\n",
    "    if status not in count_by_flight_status.keys():\n",
    "        count_by_flight_status[status] = 0\n",
    "    count_by_flight_status[status] += 1\n",
    "\n",
    "\n",
    "def append_historic_flights(flight, historic_flights):\n",
    "    if flight is not None:\n",
    "        historic_flights.append(flight)\n",
    "\n",
    "\n",
    "def is_departure_before_date(date, departure_date):\n",
    "    date = datetime.datetime.strptime(date, '%Y%m%d')\n",
    "    departure_date = datetime.datetime.strptime(departure_date, '%Y%m%d')\n",
    "    return departure_date <= date\n",
    "\n",
    "\n",
    "def is_departure_after_date(date, departure_date):\n",
    "    date = datetime.datetime.strptime(date, '%Y%m%d')\n",
    "    departure_date = datetime.datetime.strptime(departure_date, '%Y%m%d')\n",
    "    return departure_date > date\n",
    "\n",
    "\n",
    "def fetch_flight_history_by_flight_number(f, flight_number, date_start, count_by_flight_status):\n",
    "    historic_flights = []\n",
    "    has_more = True\n",
    "    page = 1\n",
    "    time_updated = int(pd.to_datetime('today').timestamp())\n",
    "    while has_more:\n",
    "        response = f.get_historical_flight_number(flight_number, time_updated, page=page)\n",
    "        if 'data' not in response:\n",
    "            default_logger.warning(\"data not in response for flight number %s, page %d\" % (flight_number, page))\n",
    "            break\n",
    "        has_more = to_has_more(response)\n",
    "        page += 1\n",
    "        for flight_response in response['data']:\n",
    "            flight = to_flight(flight_response)\n",
    "            if flight is not None:\n",
    "                time_updated = flight['time_updated']\n",
    "                departure_date = flight['departure_date']\n",
    "                if is_departure_before_date(date_end, departure_date) and is_departure_after_date(date_start,\n",
    "                                                                                                  departure_date):\n",
    "                    historic_flights.append(flight)\n",
    "                    update_count_by_flight_status(flight, count_by_flight_status)\n",
    "                if is_departure_before_date(date_start, departure_date):\n",
    "                    # default_logger.info(\"\\t departure date: %s is before date start\" % departure_date)\n",
    "                    has_more = False\n",
    "                    break\n",
    "        if page > 10:\n",
    "            break\n",
    "    # default_logger.info(\"\\t current count by flight status: %s\" % count_by_flight_status)\n",
    "    return historic_flights\n",
    "\n",
    "\n",
    "def log_summary(flights_summary_logger, flight_number, new_flights):\n",
    "    if not new_flights:\n",
    "        return\n",
    "    new_flights_df = pd.DataFrame(new_flights)\n",
    "    groups = new_flights_df.groupby(['departure_airport', 'arrival_airport'])\n",
    "    for keys, frame in groups:\n",
    "        departure_dates = frame['departure_date'].to_list()\n",
    "        flights_summary_logger.info(\"%s,%s,%s,%s,%d,%s,%s\" % (\n",
    "            pd.to_datetime('today'), flight_number, keys[0], keys[1], len(frame.index), departure_dates[-1],\n",
    "            departure_dates[0]))\n",
    "\n",
    "\n",
    "def get_start_date_by_flight_number(existing_summary, flight_number):\n",
    "    if existing_summary is not None:\n",
    "        summary = existing_summary[existing_summary[1] == flight_number]\n",
    "        if not summary.empty:\n",
    "            return str(sorted(summary[6].to_list(), reverse=True)[0])\n",
    "    return START_DATE\n",
    "\n",
    "\n",
    "def fetch_flight_history_by_country(f, unique_flights_file_prefix, historic_flights_file_prefix, country):\n",
    "    default_logger.info(\"fetching flight history for country: %s\" % country)\n",
    "    unique_flights_filename = \"%s-%s.txt\" % (unique_flights_file_prefix, country)\n",
    "    historic_flights_file_name = \"%s-%s.txt\" % (historic_flights_file_prefix, country)\n",
    "    summary_file_name = \"%s_summary-%s.txt\" % (historic_flights_file_prefix, country)\n",
    "    existing_summary = pd.read_csv(summary_file_name, usecols=[1, 7], header=None) if os.path.exists(\n",
    "        summary_file_name) else None\n",
    "    flights_summary_logger = get_flights_summary_logger(summary_file_name, country)\n",
    "    if os.path.exists(unique_flights_filename):\n",
    "        try:\n",
    "            unique_flights = pd.read_csv(unique_flights_filename).iloc[:, 0].to_list()\n",
    "            historic_flights = []\n",
    "            count_by_flight_status = {}\n",
    "            for f_idx, flight_number in enumerate(tqdm(unique_flights)):\n",
    "                date_start = get_start_date_by_flight_number(existing_summary, flight_number)\n",
    "                new_flights = fetch_flight_history_by_flight_number(f, flight_number, date_start,\n",
    "                                                                    count_by_flight_status)\n",
    "                new_df = pd.DataFrame(new_flights, columns=FLIGHTS_ATTRIBUTE_NAMES)\n",
    "                new_df.to_csv(historic_flights_file_name, mode='a', header=False, index=False)\n",
    "                log_summary(flights_summary_logger, flight_number, new_flights)\n",
    "                historic_flights.extend(new_flights)\n",
    "        except EmptyDataError:\n",
    "            default_logger.exception(\"file %s is empty\" % unique_flights_filename)\n",
    "    else:\n",
    "        default_logger.warning(\"unique flights file %s does not exist: \" % unique_flights_filename)\n",
    "\n",
    "\n",
    "def get_flights_summary_logger(file_name, country):\n",
    "    summary_logger = logging.getLogger('summary_logger_' + country)\n",
    "    handler = logging.FileHandler(file_name, mode='a')\n",
    "    handler.addFilter(InfoFilter())\n",
    "    summary_logger.addHandler(handler)\n",
    "    summary_logger.setLevel(logging.INFO)\n",
    "    return summary_logger\n",
    "\n",
    "\n",
    "def fetch_flight_history(countries,\n",
    "                         unique_flights_file_prefix=UNIQUE_FLIGHTS_FILE_PREFIX,\n",
    "                         historic_flights_file_prefix=HISTORIC_FLIGHTS_FILE_PREFIX):\n",
    "    f = CustomFlightData()\n",
    "    #f.login(\"username\", \"password\")\n",
    "    if not countries:\n",
    "        default_logger.info(\"fetching countries\")\n",
    "        countries = [country['country'] for country in f.get_countries()]\n",
    "    for country in countries:\n",
    "        fetch_flight_history_by_country(f, unique_flights_file_prefix, historic_flights_file_prefix, country)\n",
    "    f.logout()\n",
    "    \n",
    "    \n",
    "if (not os.path.exists(HISTORIC_FLIGHTS_FILE_PREFIX[:HISTORIC_FLIGHTS_FILE_PREFIX.rfind(\"/\")])):\n",
    "    os.makedirs(HISTORIC_FLIGHTS_FILE_PREFIX[:HISTORIC_FLIGHTS_FILE_PREFIX.rfind(\"/\")])\n",
    "    \n",
    "    default_logger = get_logger('logs/h_info.log', 'logs/h_error.log')\n",
    "    date_end = END_DATE\n",
    "    fetch_flight_history(countries, UNIQUE_FLIGHTS_FILE_PREFIX, HISTORIC_FLIGHTS_FILE_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d8ee303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32902/32902 [00:29<00:00, 1132.81it/s]\n"
     ]
    }
   ],
   "source": [
    "def to_node_id(airport):\n",
    "    node = airports.loc[(airports['iata'] == airport).idxmax()]\n",
    "    return node.city if not use_country and node.country == 'Vietnam' else node.country\n",
    "\n",
    "\n",
    "def append_flight_to_network(flight):\n",
    "    if flight['status'] == 'landed' or flight['status'] == 'diverted':\n",
    "        if flight['departure_date'] not in flight_network_by_date.keys():\n",
    "            flight_network_by_date[flight['departure_date']] = {}\n",
    "        adj = flight_network_by_date[flight['departure_date']]\n",
    "        srcId = to_node_id(flight['departure_airport'])\n",
    "        desId = to_node_id(flight['arrival_airport'])\n",
    "        edge = (srcId, desId)\n",
    "        if edge not in adj:\n",
    "            adj[edge] = 0\n",
    "        adj[edge] = adj[edge] + 1\n",
    "\n",
    "\n",
    "def build_flight_network():\n",
    "    total_flights = len(historic_flights.index)\n",
    "    for idx, flight in tqdm(historic_flights.iterrows(), total = total_flights):\n",
    "        append_flight_to_network(flight)\n",
    "        update_count_by_flight_status(flight, count_by_flight_status)\n",
    "\n",
    "\n",
    "def write_flight_network_to_file():\n",
    "    edge_list = []\n",
    "    for date in sorted(flight_network_by_date.keys()):\n",
    "        formatted_date = datetime.datetime.strptime(str(date), '%Y%m%d')\n",
    "        adj = flight_network_by_date[date]\n",
    "        for edge in adj.keys():\n",
    "            edge_list.append([formatted_date.strftime('%Y-%m-%d'), edge[0], edge[1], adj[edge]])\n",
    "    edge_list = pd.DataFrame(edge_list)\n",
    "    if use_country:\n",
    "        edge_list.to_csv(\"datasets/edge_lists/edge_list_all-%s.txt\" % countries[0], header=False, index=False)\n",
    "    else:\n",
    "        edge_list.to_csv(\"datasets/edge_lists/edge_list-%s.txt\" % countries[0], header=False, index=False)\n",
    "\n",
    "\n",
    "def flight_by_status_logger(unique_flights_log_file_name):\n",
    "    unique_flights_logger = logging.getLogger('flight_by_status_logger')\n",
    "    handler = logging.FileHandler(unique_flights_log_file_name, mode='a')\n",
    "    handler.addFilter(InfoFilter())\n",
    "    unique_flights_logger.addHandler(handler)\n",
    "    unique_flights_logger.setLevel(logging.INFO)\n",
    "    return unique_flights_logger\n",
    "\n",
    "if (not os.path.exists(\"datasets/edge_lists\")):\n",
    "    os.makedirs(\"datasets/edge_lists\")\n",
    "    \n",
    "    default_logger = get_logger('logs/e_info.log', 'logs/e_error.log')\n",
    "    flight_by_status_logger = flight_by_status_logger(\"datasets/edge_lists/flight_by_status.txt\")\n",
    "    _countries = pd.read_csv(COUNTRIES_FILE_NAME, header=None)\n",
    "    \n",
    "    airports = []\n",
    "    for c in _countries[0]:\n",
    "        airport_file_name = \"%s-%s.txt\" % (AIRPORTS_FILE_PREFIX, c)\n",
    "        airport = pd.read_csv(airport_file_name, names=AIRPORT_ATTRIBUTE_NAMES)\n",
    "        airports.append(airport)\n",
    "    airports = pd.concat(airports, axis=0, ignore_index=True)\n",
    "    historic_flights_file_name = \"%s-%s.txt\" % (HISTORIC_FLIGHTS_FILE_PREFIX, countries[0])\n",
    "    historic_flights = pd.read_csv(historic_flights_file_name, names=FLIGHTS_ATTRIBUTE_NAMES)\n",
    "    flight_network_by_date = {}\n",
    "    count_by_flight_status = {}\n",
    "    build_flight_network()\n",
    "    flight_by_status_logger.info(count_by_flight_status)\n",
    "    write_flight_network_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ecfb537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [00:01<00:00, 184.93it/s]\n"
     ]
    }
   ],
   "source": [
    "class generate_SIR_dataset():\n",
    "    def __init__(self):\n",
    "        self.name_to_pop = self.get_population_dict()\n",
    "        self.confirmed_df = pd.read_csv(\"datasets/covid/time_series_covid19_confirmed_global.csv\").fillna(\"\")\n",
    "        self.recovered_df = pd.read_csv(\"datasets/covid/time_series_covid19_recovered_global.csv\").fillna(\"\")\n",
    "        self.deaths_df = pd.read_csv(\"datasets/covid/time_series_covid19_deaths_global.csv\").fillna(\"\")\n",
    "        self.date = pd.to_datetime(list(self.confirmed_df.columns)[4:])\n",
    "        \n",
    "        result = self.to_df()\n",
    "        result.to_csv(\"datasets/covid_SIR.csv\", index = False)\n",
    "        return None\n",
    "    \n",
    "    def padding(self, date, values):\n",
    "        cur = 0\n",
    "        results = []\n",
    "        temp_values = 0\n",
    "        \n",
    "        for i in range(len(self.date)):\n",
    "            if (self.date[i] == datetime.datetime.strptime(date[cur], '%Y-%m-%d')):\n",
    "                results.append(values[cur])\n",
    "                temp_values = values[cur]\n",
    "                cur += 1\n",
    "            else:\n",
    "                results.append(temp_values)\n",
    "        return results\n",
    "        \n",
    "    def process_Canada(self, p):\n",
    "        Canada_df = pd.read_csv(\"datasets/covid/covid19-canada.csv\").fillna(0)\n",
    "        Canada_df = Canada_df[Canada_df[\"prname\"] == p]\n",
    "        if (len(Canada_df) == 0):\n",
    "            return [], []\n",
    "        else:\n",
    "            ii = self.padding(Canada_df[\"date\"].values.tolist(), Canada_df[\"numtotal\"].values.tolist())\n",
    "            ri = self.padding(Canada_df[\"date\"].values.tolist(), (Canada_df[\"numtotal\"].values - Canada_df[\"numactive\"].values).tolist())\n",
    "            return ii, ri\n",
    "        \n",
    "        \n",
    "    def get_population_dict(self):\n",
    "        population_df = pd.read_csv(\"datasets/covid/population.csv\").fillna(\"\")\n",
    "        return {(i+j):v for i,j,v in zip(population_df[\"Country/Region\"], population_df[\"Province/State\"], population_df[\"Population\"])}\n",
    "    \n",
    "    def to_df(self):\n",
    "        date = []\n",
    "        Country = []\n",
    "        Province = []\n",
    "        N = []\n",
    "        I = []\n",
    "        R = []\n",
    "        \n",
    "        for i, (C, P) in tqdm(enumerate(zip(self.confirmed_df[\"Country/Region\"], self.confirmed_df[\"Province/State\"])), total = len(self.confirmed_df)):\n",
    "            try:\n",
    "                confirmed_dfi = self.confirmed_df[self.confirmed_df[\"Country/Region\"] == C]\n",
    "                confirmed_dfi = confirmed_dfi[confirmed_dfi[\"Province/State\"] == P].values[0]\n",
    "                recovered_dfi = self.recovered_df[self.recovered_df[\"Country/Region\"] == C]\n",
    "                recovered_dfi = recovered_dfi[recovered_dfi[\"Province/State\"] == P].values[0]\n",
    "                deaths_dfi = self.deaths_df[self.deaths_df[\"Country/Region\"] == C]\n",
    "                if (len(deaths_dfi) == 0):\n",
    "                    deaths_dfi = np.array([0]*(len(self.date + 4)))\n",
    "                else:\n",
    "                    deaths_dfi = deaths_dfi[deaths_dfi[\"Province/State\"] == P].values[0]\n",
    "                \n",
    "                N += [self.name_to_pop[C+P]]*len(self.date)\n",
    "                date += self.date\n",
    "                Country += [C]*len(self.date)\n",
    "                Province += [P]*len(self.date)\n",
    "                I += confirmed_dfi[4:].tolist()\n",
    "                R += (recovered_dfi[4:] + deaths_dfi[4:]).tolist()\n",
    "            except:\n",
    "                if (C == \"Canada\"):\n",
    "                    ii, ri = self.process_Canada(P)\n",
    "                    if (len(ii) == 0):\n",
    "                        continue\n",
    "                    else:\n",
    "                        try:\n",
    "                            N += [self.name_to_pop[C+P]]*len(self.date)\n",
    "                            date += self.date\n",
    "                            Country += [C]*len(self.date)\n",
    "                            Province += [P]*len(self.date)\n",
    "                            I += ii\n",
    "                            R += ri\n",
    "                        except:\n",
    "                            pass\n",
    "                continue\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        df[\"date\"] = date\n",
    "        df[\"Country/Region\"] = Country\n",
    "        df[\"Province/State\"] = Province\n",
    "        df[\"N\"] = N\n",
    "        df[\"I\"] = I\n",
    "        df[\"R\"] = R\n",
    "        return df\n",
    "    \n",
    "temp = generate_SIR_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a35ae77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v3 initial # records 3724\n",
      "v3 initial # flights 32189\n",
      "removed # records 0\n",
      "v3 # records after name conversion and blacklist 3724\n",
      "Not found: South Korea\n",
      "v3 # records before write to file 3724\n",
      "v3 # flights before write to file 32189\n"
     ]
    }
   ],
   "source": [
    "NAME_CONVERSION = {\"United States\": \"US\",\n",
    "                   \"Trinidad And Tobago\": \"Trinidad and Tobago\",\n",
    "                   \"Saint Pierre And Miquelon\": \"Saint Pierre and Miquelon\",\n",
    "                   \"Antigua And Barbuda\": \"Antigua and Barbuda\",\n",
    "                   \"Saint Vincent And The Grenadines\": \"Saint Vincent and the Grenadines\",\n",
    "                   \"Saint Kitts And Nevis\": \"Saint Kitts and Nevis\",\n",
    "                   \"Turks And Caicos Islands\": \"Turks and Caicos Islands\",\n",
    "                   \"Sao Tome And Principe\": \"Sao Tome and Principe\"}\n",
    "\n",
    "BLACKLIST = []\n",
    "\n",
    "\n",
    "def assert_country_in_flight_data_has_corresponding_entry_in_covid_data(df_flights, df_covid):\n",
    "    for destination in pd.concat([df_flights['From'], df_flights['To']]).unique():\n",
    "        if destination not in df_covid['Province/State'].unique() and destination not in df_covid['Country/Region'].unique():\n",
    "            print(\"Not found:\", destination)\n",
    "\n",
    "\n",
    "# Remove country/regions in the blacklist from flights dataset\n",
    "def remove_blacklist_countries(df_flights, initial_flight_count):\n",
    "    for destination in pd.concat([df_flights['From'], df_flights['To']]).unique():\n",
    "        if destination in BLACKLIST:\n",
    "            df_flights = df_flights[df_flights['From'] != destination]\n",
    "            df_flights = df_flights[df_flights['To'] != destination]\n",
    "    print(\"removed # records\", initial_flight_count - df_flights.shape[0])\n",
    "    return df_flights\n",
    "\n",
    "\n",
    "# Align country/region names in flights and covid dataset\n",
    "def convert_country_region_names(df_flights):\n",
    "    for key in NAME_CONVERSION.keys():\n",
    "        df_flights = df_flights.replace({key: NAME_CONVERSION[key]})\n",
    "    return df_flights\n",
    "\n",
    "\n",
    "def process_flight_data():\n",
    "    filename = \"edge_list_all-\"+countries[0]+\".txt\" if use_country else \"edge_list-\"+countries[0]+\".txt\"\n",
    "    processed_filename = \"edge_list_processed_all-\"+countries[0]+\".txt\" if use_country else \"edge_list_processed-\"+countries[0]+\".txt\"\n",
    "    df_flights_v3 = pd.read_csv(\"datasets/edge_lists/%s\" % filename,\n",
    "                                names=['date', 'From', 'To', 'number of flights'])\n",
    "    df_flights_v3['date'] = pd.to_datetime(df_flights_v3['date'])\n",
    "    df_covid = pd.read_csv(\"datasets/covid_SIR.csv\")\n",
    "    df_covid['date'] = pd.to_datetime(df_covid['date'])\n",
    "\n",
    "    v3_initial_record_count = df_flights_v3.shape[0]\n",
    "    print(\"v3 initial # records\", v3_initial_record_count)\n",
    "    print(\"v3 initial # flights\", df_flights_v3['number of flights'].sum())\n",
    "\n",
    "    df_flights_v3 = remove_blacklist_countries(df_flights_v3, v3_initial_record_count)\n",
    "    df_flights_v3 = convert_country_region_names(df_flights_v3)\n",
    "    print(\"v3 # records after name conversion and blacklist\", df_flights_v3.shape[0])\n",
    "\n",
    "    assert_country_in_flight_data_has_corresponding_entry_in_covid_data(df_flights_v3, df_covid)\n",
    "\n",
    "    print(\"v3 # records before write to file\", df_flights_v3.shape[0])\n",
    "    print(\"v3 # flights before write to file\", df_flights_v3['number of flights'].sum())\n",
    "    df_flights_v3.to_csv(\"datasets/edge_lists/%s\" % processed_filename, index=False, header=False)\n",
    "\n",
    "\n",
    "process_flight_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38669b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
